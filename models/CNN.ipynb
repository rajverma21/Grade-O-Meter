{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a2fcb09-e97d-433b-80b0-28b5e91030c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "33/33 [==============================] - 2s 15ms/step - loss: 9.8107 - mae: 10.3081 - val_loss: 6.8220 - val_mae: 7.3151\n",
      "Epoch 2/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 3.9409 - mae: 4.4144 - val_loss: 2.4114 - val_mae: 2.8746\n",
      "Epoch 3/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.9207 - mae: 3.3801 - val_loss: 1.9415 - val_mae: 2.3871\n",
      "Epoch 4/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.6209 - mae: 3.0803 - val_loss: 1.7083 - val_mae: 2.1549\n",
      "Epoch 5/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 2.4141 - mae: 2.8685 - val_loss: 1.5795 - val_mae: 2.0296\n",
      "Epoch 6/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 2.0437 - mae: 2.4913 - val_loss: 1.4647 - val_mae: 1.9053\n",
      "Epoch 7/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 2.1394 - mae: 2.5977 - val_loss: 1.4080 - val_mae: 1.8500\n",
      "Epoch 8/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.9828 - mae: 2.4368 - val_loss: 1.4565 - val_mae: 1.8825\n",
      "Epoch 9/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.8978 - mae: 2.3384 - val_loss: 1.2113 - val_mae: 1.6399\n",
      "Epoch 10/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.8579 - mae: 2.3048 - val_loss: 1.0885 - val_mae: 1.5078\n",
      "Epoch 11/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 1.7214 - mae: 2.1626 - val_loss: 1.1856 - val_mae: 1.6156\n",
      "Epoch 12/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.6593 - mae: 2.1059 - val_loss: 1.0475 - val_mae: 1.4478\n",
      "Epoch 13/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.7018 - mae: 2.1433 - val_loss: 1.1182 - val_mae: 1.5542\n",
      "Epoch 14/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.5555 - mae: 1.9938 - val_loss: 0.8732 - val_mae: 1.2621\n",
      "Epoch 15/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 1.4617 - mae: 1.9000 - val_loss: 0.8703 - val_mae: 1.2590\n",
      "Epoch 16/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.4948 - mae: 1.9336 - val_loss: 1.0186 - val_mae: 1.4366\n",
      "Epoch 17/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.4248 - mae: 1.8545 - val_loss: 0.9782 - val_mae: 1.3847\n",
      "Epoch 18/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.5359 - mae: 1.9803 - val_loss: 0.7789 - val_mae: 1.1747\n",
      "Epoch 19/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.3906 - mae: 1.8236 - val_loss: 0.7175 - val_mae: 1.1076\n",
      "Epoch 20/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.3912 - mae: 1.8279 - val_loss: 0.9197 - val_mae: 1.3441\n",
      "Epoch 21/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.4055 - mae: 1.8475 - val_loss: 1.1388 - val_mae: 1.5771\n",
      "Epoch 22/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.4270 - mae: 1.8713 - val_loss: 0.6521 - val_mae: 1.0282\n",
      "Epoch 23/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.3253 - mae: 1.7633 - val_loss: 0.6589 - val_mae: 1.0446\n",
      "Epoch 24/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.2534 - mae: 1.6911 - val_loss: 0.6423 - val_mae: 1.0209\n",
      "Epoch 25/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.3133 - mae: 1.7427 - val_loss: 0.7629 - val_mae: 1.1761\n",
      "Epoch 26/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2713 - mae: 1.7035 - val_loss: 0.6007 - val_mae: 0.9783\n",
      "Epoch 27/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2750 - mae: 1.7063 - val_loss: 0.6377 - val_mae: 1.0170\n",
      "Epoch 28/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2092 - mae: 1.6435 - val_loss: 0.6033 - val_mae: 0.9847\n",
      "Epoch 29/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2561 - mae: 1.6919 - val_loss: 0.6463 - val_mae: 1.0312\n",
      "Epoch 30/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.1668 - mae: 1.6006 - val_loss: 0.6646 - val_mae: 1.0503\n",
      "Epoch 31/150\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 1.2015 - mae: 1.6264 - val_loss: 0.6337 - val_mae: 1.0209\n",
      "Epoch 32/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.2002 - mae: 1.6390 - val_loss: 0.5814 - val_mae: 0.9678\n",
      "Epoch 33/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.1466 - mae: 1.5775 - val_loss: 0.6112 - val_mae: 0.9978\n",
      "Epoch 34/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.2159 - mae: 1.6511 - val_loss: 0.5977 - val_mae: 0.9771\n",
      "Epoch 35/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.1452 - mae: 1.5725 - val_loss: 0.6149 - val_mae: 0.9956\n",
      "Epoch 36/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2197 - mae: 1.6548 - val_loss: 0.6426 - val_mae: 1.0300\n",
      "Epoch 37/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2030 - mae: 1.6362 - val_loss: 0.5566 - val_mae: 0.9358\n",
      "Epoch 38/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.1443 - mae: 1.5759 - val_loss: 0.5754 - val_mae: 0.9532\n",
      "Epoch 39/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2169 - mae: 1.6522 - val_loss: 0.5889 - val_mae: 0.9656\n",
      "Epoch 40/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.1723 - mae: 1.5964 - val_loss: 0.6623 - val_mae: 1.0538\n",
      "Epoch 41/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.0612 - mae: 1.4893 - val_loss: 0.5719 - val_mae: 0.9550\n",
      "Epoch 42/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2258 - mae: 1.6609 - val_loss: 0.5740 - val_mae: 0.9507\n",
      "Epoch 43/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.1715 - mae: 1.6071 - val_loss: 0.5897 - val_mae: 0.9731\n",
      "Epoch 44/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.1166 - mae: 1.5511 - val_loss: 0.6030 - val_mae: 0.9855\n",
      "Epoch 45/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.0993 - mae: 1.5281 - val_loss: 0.5823 - val_mae: 0.9639\n",
      "Epoch 46/150\n",
      "33/33 [==============================] - 0s 6ms/step - loss: 1.2121 - mae: 1.6418 - val_loss: 0.7147 - val_mae: 1.1233\n",
      "Epoch 47/150\n",
      "33/33 [==============================] - 0s 5ms/step - loss: 1.2179 - mae: 1.6478 - val_loss: 0.5696 - val_mae: 0.9395\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5566 - mae: 0.9358\n",
      "Mean Absolute Error on test data: 0.9357555508613586\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Predicted Final Grade (G3): 16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\KIIT\\Desktop\\8th sem project\\student-por.csv')\n",
    "\n",
    "# Selecting relevant features including G1 and G2\n",
    "features = ['G1', 'G2', 'age', 'Medu', 'Fedu', 'studytime', 'failures', \n",
    "            'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
    "target = 'G3'\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_features = ['schoolsup', 'famsup', 'higher']\n",
    "for col in categorical_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map({'yes': 1, 'no': 0})\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape input data for CNN (adding a dimension)\n",
    "X_scaled = X_scaled.reshape(-1, X_scaled.shape[1], 1)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation='linear')  # Regression output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='huber_loss', metrics=['mae'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=16, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error on test data: {mae}')\n",
    "\n",
    "# Function for predicting student performance\n",
    "def predict_performance(new_data):\n",
    "    new_data_df = pd.DataFrame([new_data], columns=features)\n",
    "    new_data_scaled = scaler.transform(new_data_df).reshape(-1, len(features), 1)\n",
    "    prediction = model.predict(new_data_scaled)\n",
    "    return round(prediction[0][0])\n",
    "\n",
    "# Example prediction (ensure G1 and G2 are provided)\n",
    "new_student = [13, 1, 18, 4, 4, 2, 0, 3, 3, 1, 1, 5, 4]\n",
    "predicted_score = predict_performance(new_student)\n",
    "print(f'Predicted Final Grade (G3): {predicted_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54757fc-af82-4eaf-af62-aadec667ed11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
